{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of test of parity scaling laws in Jupyter notebook.\n",
    "\n",
    "The code contained here is very similar to that in the rest of the repo, but is not guarenteed to be identical.\n",
    "\n",
    "This notebook is included for ease of use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (1.26.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (4.66.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.11/site-packages (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.11/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /opt/conda/lib/python3.11/site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/conda/lib/python3.11/site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /opt/conda/lib/python3.11/site-packages (from seaborn) (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (2.4.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "Requirement already satisfied: pathlib in /opt/conda/lib/python3.11/site-packages (1.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Package imports\n",
    "\n",
    "# pip install if necessary\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install tqdm\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install torch\n",
    "!pip install pathlib\n",
    "\n",
    "# Standard library imports (no pip install needed)\n",
    "import logging  # built-in module\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "# Third part imports (pip install may be required. See requirements.txt if looking to run the rest of the python project)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime\n",
    "import os\n",
    "from typing import Tuple, Dict # if used, this should be moved to the import section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# Parameters\n",
    "PARAMS = {\n",
    "    'n_tasks': 1, # number of unique tasks being trained over\n",
    "    'len_taskcode': 4, # number of bits in the task code\n",
    "    'num_checks': 5, # number of bits in the message that are used to determine the output\n",
    "    'len_message': 16, # number of bits in the message\n",
    "    'num_samples': 1000, # number of samples to generate for each task, per 'epoch' (in the infinite data regime, terminology is slightly abused)\n",
    "    'input_size': 20,  # len_taskcode + len_message. Used for model initialisation\n",
    "    'output_size': 1, # output size of the model. 1 for binary classification. Do not change\n",
    "    'learning_rate': 0.005, # constant learning rate. Could introduce a scheduler?\n",
    "    'batch_size': 32, # batch size used in training. Will be the same throughout a run\n",
    "    'flop_budget': 1e12, # total number of estimated flops expended per training run\n",
    "    'task_sample_freq': 1e12/1e3,  # the rate at which performance is evaluated. Can give a big performance hit\n",
    "    'plot_freq': 1e12/20,  # Frequency of created plots. Note that this is also the frequency at which data is saved \n",
    "    # a large plot_freq can result in significant memory consumption\n",
    "    'samples_per_task': 100 # number of samples to generate for each task in evaluation\n",
    "    # Note: samples_per_task is not very relevant when there is only one task, as it reproduces earlier calculations exactly\n",
    "}\n",
    "\n",
    "# Define a range of model configurations\n",
    "model_configs = [\n",
    "    {\"num_layers\": 2, \"hidden_size\": 8},\n",
    "    {\"num_layers\": 4, \"hidden_size\": 16},\n",
    "    {\"num_layers\": 6, \"hidden_size\": 32},\n",
    "    {\"num_layers\": 8, \"hidden_size\": 64},\n",
    "    {\"num_layers\": 10, \"hidden_size\": 128},\n",
    "    {\"num_layers\": 12, \"hidden_size\": 256},\n",
    "    {\"num_layers\": 14, \"hidden_size\": 512} \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "    \n",
    "def generate_random_binary_string(length):\n",
    "    # Random binary string of length 'length'\n",
    "    return ''.join(random.choice(['0', '1']) for _ in range(length))\n",
    "\n",
    "def generate_dict(n_tasks, len_taskcode, num_checks, len_message):\n",
    "    # Generate the task codes and their associated check bits\n",
    "    unique_strings = set()\n",
    "    tasks_dict = {}\n",
    "    while len(unique_strings) < n_tasks:\n",
    "        binary_string = generate_random_binary_string(len_taskcode)\n",
    "        if binary_string not in unique_strings:\n",
    "            unique_strings.add(binary_string)\n",
    "            integer_list = [random.randint(0, len_message-1) for _ in range(num_checks)]\n",
    "            tasks_dict[binary_string] = integer_list\n",
    "    return tasks_dict\n",
    "\n",
    "def generate_dataset(tasks_dict, num_samples, len_taskcode, len_message):\n",
    "    # Generate a dataset of num_samples samples using tasks specified in tasks_dict\n",
    "    data = np.zeros((num_samples, len_taskcode + len_message))\n",
    "    value = np.zeros(num_samples)\n",
    "    for i in range(num_samples):\n",
    "        rand_task = np.random.choice(list(tasks_dict))\n",
    "        rand_checkbits = tasks_dict[rand_task]\n",
    "        message = generate_random_binary_string(len_message)\n",
    "        parity_bit = sum(int(message[j]) for j in rand_checkbits) % 2\n",
    "        data[i] = np.concatenate((np.array(list(rand_task)), np.array(list(message))))\n",
    "        value[i] = parity_bit\n",
    "    return [data, value]\n",
    "\n",
    "def generate_dataset_for_task(task_code, tasks_dict, num_samples, len_taskcode, len_message):\n",
    "    # Generate a dataset of num_samples samples for a specific task\n",
    "    # Used primarily for evaluation. Very limited performance improvement from generate_dataset\n",
    "    data = np.zeros((num_samples, len_taskcode + len_message))\n",
    "    value = np.zeros(num_samples)\n",
    "    rand_checkbits = tasks_dict[task_code]\n",
    "    for i in range(num_samples):\n",
    "        message = generate_random_binary_string(len_message)\n",
    "        parity_bit = sum(int(message[j]) for j in rand_checkbits) % 2\n",
    "        data[i] = np.concatenate((np.array(list(task_code)), np.array(list(message))))\n",
    "        value[i] = parity_bit\n",
    "    return [data, value]\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, device):\n",
    "        # Convert to numpy first for efficiency\n",
    "        data_np = dataframe.iloc[:, :-1].values\n",
    "        target_np = dataframe.iloc[:, -1].values\n",
    "        \n",
    "        # Single transfer to device. IO-aware for greater efficiency\n",
    "        self.data = torch.from_numpy(data_np).float().to(device)\n",
    "        self.target = torch.from_numpy(target_np).float().to(device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.target[idx]\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_layers, hidden_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(nn.Linear(input_size, hidden_size))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "            self.layers.append(nn.BatchNorm1d(hidden_size))\n",
    "        self.layers.append(nn.Linear(hidden_size, output_size))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for i, layer in enumerate(self.layers[:-1]):\n",
    "            if i == 0:\n",
    "                x = F.relu(layer(x))\n",
    "            else:\n",
    "                x = layer(x)\n",
    "                if i % 2 == 0:\n",
    "                    x = F.relu(x)\n",
    "        x = self.layers[-1](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot intermediate progress\n",
    "\n",
    "def plot_progress(loss_data, accuracy_data, task_accuracy_data, cumulative_flops, exp_dir):\n",
    "    \"\"\"\n",
    "    Plot and save training progress.\n",
    "    \n",
    "    Args:\n",
    "        loss_data: List of tuples (flops, loss)\n",
    "        accuracy_data: List of tuples (flops, accuracy)\n",
    "        task_accuracy_data: Dict of lists of tuples (flops, accuracy) for each task\n",
    "        cumulative_flops: Current total FLOPs\n",
    "        exp_dir: Path to experiment directory\n",
    "    \"\"\"\n",
    "    # Create plots directory if it doesn't exist\n",
    "    plots_dir = exp_dir / \"intermediate_plots\"\n",
    "    plots_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Create figure with multiple subplots\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Plot loss\n",
    "    flops_loss, losses = zip(*loss_data)\n",
    "    ax1.plot(flops_loss, losses)\n",
    "    ax1.set_xlabel('FLOPs')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Training Loss vs FLOPs')\n",
    "    ax1.set_xscale('log')\n",
    "    ax1.set_yscale('log')\n",
    "    \n",
    "    # Plot overall accuracy\n",
    "    flops_acc, accuracies = zip(*accuracy_data)\n",
    "    ax2.plot(flops_acc, accuracies)\n",
    "    ax2.set_xlabel('FLOPs')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_title('Overall Accuracy vs FLOPs')\n",
    "    ax2.set_xscale('log')\n",
    "    \n",
    "    # Plot task-specific accuracies\n",
    "    for task_idx, task_data in task_accuracy_data.items():\n",
    "        if task_data:  # Check if there's data for this task\n",
    "            flops_task, task_accuracies = zip(*task_data)\n",
    "            ax3.plot(flops_task, task_accuracies, label=f'Task {task_idx}')\n",
    "    ax3.set_xlabel('FLOPs')\n",
    "    ax3.set_ylabel('Accuracy')\n",
    "    ax3.set_title('Task-Specific Accuracy vs FLOPs')\n",
    "    ax3.set_xscale('log')\n",
    "    ax3.legend()\n",
    "    \n",
    "    # Adjust layout and save\n",
    "    plt.tight_layout()\n",
    "    plot_path = plots_dir / f\"progress_{cumulative_flops:.2e}_flops.png\"\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()\n",
    "    \n",
    "    # Log the plot creation\n",
    "    logging.info(f\"Saved progress plot at {cumulative_flops:.2e} FLOPs to {plot_path}\")\n",
    "    \n",
    "    # Also save the data as CSV for later analysis\n",
    "    data_dir = exp_dir / \"intermediate_data\"\n",
    "    data_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Save loss and accuracy data\n",
    "    df_metrics = pd.DataFrame({\n",
    "        'flops': flops_loss,\n",
    "        'loss': losses,\n",
    "        'accuracy': accuracies\n",
    "    })\n",
    "    df_metrics.to_csv(data_dir / f\"metrics_{cumulative_flops:.2e}_flops.csv\", index=False)\n",
    "    \n",
    "    # Save task-specific accuracy data\n",
    "    task_data_dict = {}\n",
    "    for task_idx, task_data in task_accuracy_data.items():\n",
    "        if task_data:\n",
    "            flops_task, task_accuracies = zip(*task_data)\n",
    "            task_data_dict[f'task_{task_idx}_flops'] = flops_task\n",
    "            task_data_dict[f'task_{task_idx}_accuracy'] = task_accuracies\n",
    "    \n",
    "    df_tasks = pd.DataFrame(task_data_dict)\n",
    "    df_tasks.to_csv(data_dir / f\"task_accuracies_{cumulative_flops:.2e}_flops.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main plot\n",
    "\n",
    "def main_plot(all_results, exp_dir):\n",
    "    \"\"\"\n",
    "    Create final plots comparing all model configurations.\n",
    "    \n",
    "    Args:\n",
    "        all_results: List of dictionaries containing results for each model config\n",
    "        exp_dir: Path to experiment directory\n",
    "    \"\"\"\n",
    "    # Extract data from results\n",
    "    all_loss_data = []\n",
    "    all_accuracy_data = []\n",
    "    all_task_accuracy_data = []\n",
    "    all_flops = []\n",
    "    \n",
    "    for result in all_results:\n",
    "        all_loss_data.append(result['loss_data'])\n",
    "        all_accuracy_data.append(result['accuracy_data'])\n",
    "        all_task_accuracy_data.append(result['task_accuracy_data'])\n",
    "        all_flops.append(result['cumulative_flops'])\n",
    "\n",
    "    # Create final plots\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(1, 3, 1)\n",
    "    for i, config in enumerate(MODEL_CONFIGS):\n",
    "        flops, losses = zip(*all_loss_data[i])\n",
    "        plt.loglog(flops, losses, label=f'{config[\"num_layers\"]}x{config[\"hidden_size\"]}')\n",
    "    plt.xlabel('Cumulative FLOPs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss vs FLOPs')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot overall accuracy\n",
    "    plt.subplot(1, 3, 2)\n",
    "    for i, config in enumerate(MODEL_CONFIGS):\n",
    "        flops, accuracies = zip(*all_accuracy_data[i])\n",
    "        plt.semilogx(flops, accuracies, label=f'{config[\"num_layers\"]}x{config[\"hidden_size\"]}')\n",
    "    plt.xlabel('Cumulative FLOPs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy vs FLOPs')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot task-specific accuracies\n",
    "    plt.subplot(1, 3, 3)\n",
    "    for i, config in enumerate(MODEL_CONFIGS):\n",
    "        for task in range(PARAMS['n_tasks']):\n",
    "            flops, accuracies = zip(*all_task_accuracy_data[i][task])\n",
    "            plt.semilogx(flops, accuracies, \n",
    "                        label=f'Task {task+1} - {config[\"num_layers\"]}x{config[\"hidden_size\"]}')\n",
    "    plt.xlabel('Cumulative FLOPs')\n",
    "    plt.ylabel('Task-specific Accuracy')\n",
    "    plt.title('Task-specific Accuracies vs FLOPs')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plot_path = exp_dir / \"final_comparison.png\"\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()\n",
    "    \n",
    "    logging.info(f\"Saved final comparison plot to {plot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count FLOPs\n",
    "\n",
    "# No longer in use. fvcore seems to have given unreliable results, although this may down to my quite simplistic counting of flops\n",
    "#def count_flops_fvcore(model, input_size):\n",
    "#    input_tensor = torch.randn(2, input_size)\n",
    "#    flops = FlopCountAnalysis(model, input_tensor)\n",
    "#    return flops.total() // 2\n",
    "\n",
    "class FlopCounter:\n",
    "    def __init__(self, model: nn.Module, input_size: int, batch_size: int):\n",
    "        self.model = model\n",
    "        self.input_size = input_size\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def count_linear_flops(self, in_features: int, out_features: int) -> Dict[str, int]:\n",
    "        \"\"\"\n",
    "        Count FLOPs for linear layer operations.\n",
    "        Forward: Each output element requires in_features multiplications and in_features-1 additions\n",
    "        Backward: Requires computing gradients for weights, biases, and input\n",
    "        \"\"\"\n",
    "        forward_flops = self.batch_size * out_features * (2 * in_features - 1)  # mult-add pairs\n",
    "        \n",
    "        # Backward pass FLOPs:\n",
    "        # 1. dL/dW computation: batch_size * in_features * out_features * 2\n",
    "        # 2. dL/db computation: batch_size * out_features\n",
    "        # 3. dL/dx computation: batch_size * in_features * out_features * 2\n",
    "        backward_flops = (\n",
    "            self.batch_size * in_features * out_features * 2 +  # dL/dW\n",
    "            self.batch_size * out_features +                    # dL/db\n",
    "            self.batch_size * in_features * out_features * 2    # dL/dx\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"forward\": forward_flops,\n",
    "            \"backward\": backward_flops\n",
    "        }\n",
    "    \n",
    "    def count_batch_norm_flops(self, num_features: int) -> Dict[str, int]:\n",
    "        \"\"\"\n",
    "        Count FLOPs for batch normalization operations.\n",
    "        Forward: Computing mean, variance, normalized values, and scaling\n",
    "        Backward: Computing gradients for gamma, beta, and input\n",
    "        \"\"\"\n",
    "        # Forward pass operations per feature:\n",
    "        # 1. Mean calculation: batch_size additions\n",
    "        # 2. Variance calculation: batch_size multiplications and additions\n",
    "        # 3. Normalization: 4 operations per element (subtract mean, divide by std)\n",
    "        # 4. Scale and shift: 2 operations per element\n",
    "        forward_flops = self.batch_size * num_features * (7)\n",
    "        \n",
    "        # Backward pass operations:\n",
    "        # 1. Gradients for gamma and beta: batch_size additions per feature\n",
    "        # 2. Gradients for input: ~8 operations per element\n",
    "        backward_flops = self.batch_size * num_features * 10\n",
    "        \n",
    "        return {\n",
    "            \"forward\": forward_flops,\n",
    "            \"backward\": backward_flops\n",
    "        }\n",
    "    \n",
    "    def count_relu_flops(self, num_elements: int) -> Dict[str, int]:\n",
    "        \"\"\"\n",
    "        Count FLOPs for ReLU activation.\n",
    "        Forward: One comparison per element\n",
    "        Backward: One multiplication per element (gradient is 0 or 1)\n",
    "        \"\"\"\n",
    "        forward_flops = num_elements  # One comparison per element\n",
    "        backward_flops = num_elements  # One multiplication per element\n",
    "        \n",
    "        return {\n",
    "            \"forward\": forward_flops,\n",
    "            \"backward\": backward_flops\n",
    "        }\n",
    "    \n",
    "    def calculate_total_flops(self) -> Tuple[int, int]:\n",
    "        \"\"\"\n",
    "        Calculate total FLOPs for both forward and backward passes through the entire model.\n",
    "        Returns tuple of (forward_flops, backward_flops)\n",
    "        \"\"\"\n",
    "        total_forward_flops = 0\n",
    "        total_backward_flops = 0\n",
    "        \n",
    "        current_size = self.input_size\n",
    "        \n",
    "        for layer in self.model.layers:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                flops = self.count_linear_flops(layer.in_features, layer.out_features)\n",
    "                total_forward_flops += flops[\"forward\"]\n",
    "                total_backward_flops += flops[\"backward\"]\n",
    "                current_size = layer.out_features\n",
    "                \n",
    "            elif isinstance(layer, nn.BatchNorm1d):\n",
    "                flops = self.count_batch_norm_flops(current_size)\n",
    "                total_forward_flops += flops[\"forward\"]\n",
    "                total_backward_flops += flops[\"backward\"]\n",
    "                \n",
    "            # Count ReLU FLOPs after linear layers (except the last one)\n",
    "            if isinstance(layer, nn.Linear) and layer != self.model.layers[-1]:\n",
    "                flops = self.count_relu_flops(self.batch_size * current_size)\n",
    "                total_forward_flops += flops[\"forward\"]\n",
    "                total_backward_flops += flops[\"backward\"]\n",
    "        \n",
    "        return total_forward_flops, total_backward_flops\n",
    "\n",
    "def get_flops_per_pass(model: nn.Module, input_size: int, batch_size: int) -> Tuple[int, int]:\n",
    "    \"\"\"\n",
    "    Wrapper function to get FLOPs per forward and backward pass.\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch neural network model\n",
    "        input_size: Size of input features\n",
    "        batch_size: Batch size used in training\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (forward_flops, backward_flops)\n",
    "    \"\"\"\n",
    "    counter = FlopCounter(model, input_size, batch_size)\n",
    "    return counter.calculate_total_flops()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Managing saving of files\n",
    "\n",
    "def create_versioned_directory(base_dir: Path, name: str) -> Path:\n",
    "    \"\"\"\n",
    "    Create a versioned directory to avoid overwriting existing experiments.\n",
    "    \n",
    "    Args:\n",
    "        base_dir: Base directory for experiments\n",
    "        name: Base name for the experiment directory\n",
    "        \n",
    "    Returns:\n",
    "        Path: Path to the created directory\n",
    "    \"\"\"\n",
    "    base_dir.mkdir(exist_ok=True)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    version = 1\n",
    "    \n",
    "    while True:\n",
    "        versioned_name = f\"{name}__{timestamp}_v{version}\"\n",
    "        dir_path = base_dir / versioned_name\n",
    "        if not dir_path.exists():\n",
    "            dir_path.mkdir()\n",
    "            return dir_path\n",
    "        version += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "\n",
    "# This function has been significantly modified to incorporate the new count FLOPs function\n",
    "# There may be bugs down the line related to how data is collected and displayed. This should be more thoroughly debugged\n",
    "\n",
    "def train_and_evaluate(model, params, tasks_dict, exp_dir, model_config):\n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Move model to device\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Initialize criterion and optimizer\n",
    "    criterion = nn.BCEWithLogitsLoss() # Identical to BCE, except for application of sigmoid to the outputs. Gives smoother loss\n",
    "    optimizer = optim.SGD(model.parameters(), lr=params['learning_rate'])\n",
    "    \n",
    "    # Initialize FlopCounter\n",
    "    flop_counter = FlopCounter(model, input_size=params['input_size'], batch_size=params['batch_size'])\n",
    "    forward_flops, backward_flops = flop_counter.calculate_total_flops()\n",
    "    \n",
    "    loss_data = []\n",
    "    accuracy_data = []\n",
    "    task_accuracy_data = {i: [] for i in range(params['n_tasks'])}\n",
    "    cumulative_flops = 0\n",
    "    epoch = 0\n",
    "    last_task_sample = 0\n",
    "    last_plot = 0\n",
    "\n",
    "    print_rate = params['flop_budget'] / 1e1 # prints only when the FLOP budget is reached\n",
    "    disp_flops = 0\n",
    "    \n",
    "    while cumulative_flops < params['flop_budget']:\n",
    "        if cumulative_flops - print_rate > disp_flops:\n",
    "            print(f'cumulative_flops: {cumulative_flops} - flop_budget: {params[\"flop_budget\"]} - Percentage completion: {(cumulative_flops/params[\"flop_budget\"])*100:.2f}%')\n",
    "            disp_flops = cumulative_flops\n",
    "            \n",
    "        epoch += 1\n",
    "        [data, value] = generate_dataset(tasks_dict, params['num_samples'], \n",
    "                                       params['len_taskcode'], params['len_message'])\n",
    "        df = pd.DataFrame(np.concatenate((data, value.reshape(-1, 1)), axis=1))\n",
    "        \n",
    "        dataset = CustomDataset(df, device)\n",
    "        data_loader = DataLoader(dataset, batch_size=params['batch_size'], shuffle=True)\n",
    "        \n",
    "        epoch_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        model.train()\n",
    "\n",
    "        for inputs, labels in data_loader:\n",
    "            outputs = model(inputs)\n",
    "            batch_loss = criterion(outputs, labels.unsqueeze(1))\n",
    "            predictions = (outputs >= 0.5).squeeze().long()\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += batch_loss.item() * inputs.size(0)\n",
    "            \n",
    "            # Calculate FLOPs\n",
    "            batch_flops = forward_flops + backward_flops\n",
    "            cumulative_flops += batch_flops\n",
    "\n",
    "        avg_loss = epoch_loss / len(dataset)\n",
    "        avg_accuracy = correct / total\n",
    "\n",
    "        loss_data.append((cumulative_flops, avg_loss))\n",
    "        accuracy_data.append((cumulative_flops, avg_accuracy))\n",
    "        \n",
    "        # Task-specific evaluation\n",
    "        if cumulative_flops - last_task_sample >= params['task_sample_freq'] or cumulative_flops >= params['flop_budget']:\n",
    "            last_task_sample = cumulative_flops\n",
    "            \n",
    "            for task_idx, task_code in enumerate(tasks_dict.keys()):\n",
    "                [data_per_task, value_per_task] = generate_dataset_for_task(\n",
    "                    task_code, tasks_dict, params['samples_per_task'],\n",
    "                    params['len_taskcode'], params['len_message']\n",
    "                )\n",
    "                df_per_task = pd.DataFrame(np.concatenate((data_per_task, value_per_task.reshape(-1, 1)), axis=1))\n",
    "                dataset_per_task = CustomDataset(df_per_task, device)\n",
    "                loader_per_task = DataLoader(dataset_per_task, batch_size=params['batch_size'], shuffle=True)\n",
    "                \n",
    "                model.eval()\n",
    "                task_correct = 0\n",
    "                task_total = 0\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    for inputs, labels in loader_per_task:\n",
    "                        outputs = model(inputs)\n",
    "                        predictions = (outputs >= 0.5).squeeze().long()\n",
    "                        task_correct += (predictions == labels).sum().item()\n",
    "                        task_total += labels.size(0)\n",
    "                        cumulative_flops += forward_flops\n",
    "                        \n",
    "                task_accuracy = task_correct / task_total\n",
    "                task_accuracy_data[task_idx].append((cumulative_flops, task_accuracy))\n",
    "\n",
    "        if cumulative_flops - last_plot >= params['plot_freq']:\n",
    "            last_plot = cumulative_flops\n",
    "            plot_progress(loss_data, accuracy_data, task_accuracy_data, cumulative_flops, exp_dir)\n",
    "\n",
    "    return { # loss_data, accuracy_data, task_accuracy_data, cumulative_flops\n",
    "        'loss_data': loss_data,\n",
    "        'accuracy_data': accuracy_data,\n",
    "        'task_accuracy_data': task_accuracy_data,\n",
    "        'cumulative_flops': cumulative_flops,\n",
    "        'model_config': model_config\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Experiment directory: experiments/parity_scaling_flops_1e+12__20250108_005311_v1\n",
      "FLOP budget: 1000000000000.0\n",
      "Generated tasks dictionary with 1 tasks\n",
      "tasks_dict =  dict_items([('1011', [7, 14, 5, 4, 3])])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 2 layers and hidden size 8\n",
      "Using device: cuda\n",
      "cumulative_flops: 100000646784 - flop_budget: 1000000000000.0 - Percentage completion: 10.00%\n",
      "cumulative_flops: 200001336448 - flop_budget: 1000000000000.0 - Percentage completion: 20.00%\n",
      "cumulative_flops: 300002026112 - flop_budget: 1000000000000.0 - Percentage completion: 30.00%\n",
      "cumulative_flops: 400002715776 - flop_budget: 1000000000000.0 - Percentage completion: 40.00%\n",
      "cumulative_flops: 500003405440 - flop_budget: 1000000000000.0 - Percentage completion: 50.00%\n",
      "cumulative_flops: 600004095104 - flop_budget: 1000000000000.0 - Percentage completion: 60.00%\n",
      "cumulative_flops: 700004784768 - flop_budget: 1000000000000.0 - Percentage completion: 70.00%\n",
      "cumulative_flops: 800005474432 - flop_budget: 1000000000000.0 - Percentage completion: 80.00%\n",
      "cumulative_flops: 900006164096 - flop_budget: 1000000000000.0 - Percentage completion: 90.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:  14%|█▍        | 1/7 [15:21:44<92:10:27, 55304.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 4 layers and hidden size 16\n",
      "Using device: cuda\n",
      "cumulative_flops: 100001287808 - flop_budget: 1000000000000.0 - Percentage completion: 10.00%\n",
      "cumulative_flops: 200002821248 - flop_budget: 1000000000000.0 - Percentage completion: 20.00%\n",
      "cumulative_flops: 300004354688 - flop_budget: 1000000000000.0 - Percentage completion: 30.00%\n",
      "cumulative_flops: 400005642496 - flop_budget: 1000000000000.0 - Percentage completion: 40.00%\n",
      "cumulative_flops: 500007175936 - flop_budget: 1000000000000.0 - Percentage completion: 50.00%\n",
      "cumulative_flops: 600008709376 - flop_budget: 1000000000000.0 - Percentage completion: 60.00%\n",
      "cumulative_flops: 700009997184 - flop_budget: 1000000000000.0 - Percentage completion: 70.00%\n",
      "cumulative_flops: 800011530624 - flop_budget: 1000000000000.0 - Percentage completion: 80.00%\n",
      "cumulative_flops: 900013064064 - flop_budget: 1000000000000.0 - Percentage completion: 90.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:  29%|██▊       | 2/7 [19:37:34<44:10:10, 31802.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 6 layers and hidden size 32\n",
      "Using device: cuda\n",
      "cumulative_flops: 100014001920 - flop_budget: 1000000000000.0 - Percentage completion: 10.00%\n",
      "cumulative_flops: 200028003840 - flop_budget: 1000000000000.0 - Percentage completion: 20.00%\n",
      "cumulative_flops: 300042005760 - flop_budget: 1000000000000.0 - Percentage completion: 30.00%\n",
      "cumulative_flops: 400056007680 - flop_budget: 1000000000000.0 - Percentage completion: 40.01%\n",
      "cumulative_flops: 500070009600 - flop_budget: 1000000000000.0 - Percentage completion: 50.01%\n",
      "cumulative_flops: 600084011520 - flop_budget: 1000000000000.0 - Percentage completion: 60.01%\n",
      "cumulative_flops: 700098013440 - flop_budget: 1000000000000.0 - Percentage completion: 70.01%\n",
      "cumulative_flops: 800112015360 - flop_budget: 1000000000000.0 - Percentage completion: 80.01%\n",
      "cumulative_flops: 900126017280 - flop_budget: 1000000000000.0 - Percentage completion: 90.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:  43%|████▎     | 3/7 [20:36:49<21:00:15, 18903.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 8 layers and hidden size 64\n",
      "Using device: cuda\n",
      "cumulative_flops: 100136341120 - flop_budget: 1000000000000.0 - Percentage completion: 10.01%\n",
      "cumulative_flops: 200272682240 - flop_budget: 1000000000000.0 - Percentage completion: 20.03%\n",
      "cumulative_flops: 300416002816 - flop_budget: 1000000000000.0 - Percentage completion: 30.04%\n",
      "cumulative_flops: 400552343936 - flop_budget: 1000000000000.0 - Percentage completion: 40.06%\n",
      "cumulative_flops: 500688685056 - flop_budget: 1000000000000.0 - Percentage completion: 50.07%\n",
      "cumulative_flops: 600832005632 - flop_budget: 1000000000000.0 - Percentage completion: 60.08%\n",
      "cumulative_flops: 700968346752 - flop_budget: 1000000000000.0 - Percentage completion: 70.10%\n",
      "cumulative_flops: 801104687872 - flop_budget: 1000000000000.0 - Percentage completion: 80.11%\n",
      "cumulative_flops: 901248008448 - flop_budget: 1000000000000.0 - Percentage completion: 90.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:  57%|█████▋    | 4/7 [20:51:47<9:49:45, 11795.24s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 10 layers and hidden size 128\n",
      "Using device: cuda\n",
      "cumulative_flops: 100554040064 - flop_budget: 1000000000000.0 - Percentage completion: 10.06%\n",
      "cumulative_flops: 201143240064 - flop_budget: 1000000000000.0 - Percentage completion: 20.11%\n",
      "cumulative_flops: 301697280128 - flop_budget: 1000000000000.0 - Percentage completion: 30.17%\n",
      "cumulative_flops: 402286480128 - flop_budget: 1000000000000.0 - Percentage completion: 40.23%\n",
      "cumulative_flops: 502840520192 - flop_budget: 1000000000000.0 - Percentage completion: 50.28%\n",
      "cumulative_flops: 603429720192 - flop_budget: 1000000000000.0 - Percentage completion: 60.34%\n",
      "cumulative_flops: 703983760256 - flop_budget: 1000000000000.0 - Percentage completion: 70.40%\n",
      "cumulative_flops: 804572960256 - flop_budget: 1000000000000.0 - Percentage completion: 80.46%\n",
      "cumulative_flops: 905127000320 - flop_budget: 1000000000000.0 - Percentage completion: 90.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:  71%|███████▏  | 5/7 [20:55:21<4:13:57, 7618.85s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 12 layers and hidden size 256\n",
      "Using device: cuda\n",
      "cumulative_flops: 102752056320 - flop_budget: 1000000000000.0 - Percentage completion: 10.28%\n",
      "cumulative_flops: 205504112640 - flop_budget: 1000000000000.0 - Percentage completion: 20.55%\n",
      "cumulative_flops: 308256168960 - flop_budget: 1000000000000.0 - Percentage completion: 30.83%\n",
      "cumulative_flops: 411008225280 - flop_budget: 1000000000000.0 - Percentage completion: 41.10%\n",
      "cumulative_flops: 513760281600 - flop_budget: 1000000000000.0 - Percentage completion: 51.38%\n",
      "cumulative_flops: 616512337920 - flop_budget: 1000000000000.0 - Percentage completion: 61.65%\n",
      "cumulative_flops: 719264394240 - flop_budget: 1000000000000.0 - Percentage completion: 71.93%\n",
      "cumulative_flops: 822016450560 - flop_budget: 1000000000000.0 - Percentage completion: 82.20%\n",
      "cumulative_flops: 924768506880 - flop_budget: 1000000000000.0 - Percentage completion: 92.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:  86%|████████▌ | 6/7 [20:56:18<1:24:07, 5047.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 14 layers and hidden size 512\n",
      "Using device: cuda\n",
      "cumulative_flops: 101637815680 - flop_budget: 1000000000000.0 - Percentage completion: 10.16%\n",
      "cumulative_flops: 203275631360 - flop_budget: 1000000000000.0 - Percentage completion: 20.33%\n",
      "cumulative_flops: 304913447040 - flop_budget: 1000000000000.0 - Percentage completion: 30.49%\n",
      "cumulative_flops: 406551262720 - flop_budget: 1000000000000.0 - Percentage completion: 40.66%\n",
      "cumulative_flops: 508189078400 - flop_budget: 1000000000000.0 - Percentage completion: 50.82%\n",
      "cumulative_flops: 609826894080 - flop_budget: 1000000000000.0 - Percentage completion: 60.98%\n",
      "cumulative_flops: 711464709760 - flop_budget: 1000000000000.0 - Percentage completion: 71.15%\n",
      "cumulative_flops: 813102525440 - flop_budget: 1000000000000.0 - Percentage completion: 81.31%\n",
      "cumulative_flops: 914740341120 - flop_budget: 1000000000000.0 - Percentage completion: 91.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models: 100%|██████████| 7/7 [20:56:39<00:00, 10771.31s/it] \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "main_plot() missing 2 required positional arguments: 'all_task_accuracy_data' and 'all_flops'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m     main_plot(all_results, exp_dir)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 48\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[9], line 45\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m     all_results\u001b[38;5;241m.\u001b[39mappend(results)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Create final plots\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m main_plot(all_results, exp_dir)\n",
      "\u001b[0;31mTypeError\u001b[0m: main_plot() missing 2 required positional arguments: 'all_task_accuracy_data' and 'all_flops'"
     ]
    }
   ],
   "source": [
    "# Main\n",
    "\n",
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Create experiment directory\n",
    "    exp_name = f\"parity_scaling_flops_{PARAMS['flop_budget']:.0e}\"\n",
    "    exp_dir = create_versioned_directory(Path(\"experiments\"), exp_name)\n",
    "    print(f\"Experiment directory: {exp_dir}\")\n",
    "\n",
    "    print(f\"FLOP budget: {PARAMS['flop_budget']}\")\n",
    "    \n",
    "    tasks_dict = generate_dict(\n",
    "        PARAMS['n_tasks'], \n",
    "        PARAMS['len_taskcode'], \n",
    "        PARAMS['num_checks'], \n",
    "        PARAMS['len_message']\n",
    "    )\n",
    "    print(f\"Generated tasks dictionary with {len(tasks_dict)} tasks\")\n",
    "    print(\"tasks_dict = \", tasks_dict.items())\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    # Add progress bar for model configurations\n",
    "    for config in tqdm(model_configs, desc=\"Training models\", position=0, leave=True):\n",
    "        print(f\"\\nTraining model with {config['num_layers']} layers and hidden size {config['hidden_size']}\")\n",
    "        model = NeuralNetwork(\n",
    "            PARAMS['input_size'], \n",
    "            PARAMS['output_size'], \n",
    "            config[\"num_layers\"], \n",
    "            config[\"hidden_size\"]\n",
    "        ).to(device)\n",
    "        # model, criterion, optimizer, flop_budget, tasks_dict\n",
    "        results = train_and_evaluate(\n",
    "            model=model,\n",
    "            params=PARAMS,\n",
    "            tasks_dict=tasks_dict,\n",
    "            exp_dir=exp_dir,\n",
    "            model_config=config\n",
    "        )\n",
    "        all_results.append(results)\n",
    "    \n",
    "    # Create final plots\n",
    "    main_plot(all_results, exp_dir)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /workspace/project\n",
      "Looking for directory: /workspace/project/experiments/parity_scaling_flops_1e+12__20250108_005311_v1\n"
     ]
    }
   ],
   "source": [
    "# Optional post-processing function\n",
    "import os\n",
    "def create_seaborn_plots(exp_dir: Path, epoch_window: int = 10, confidence_interval: float = 0.95):\n",
    "    \"\"\"Create seaborn plots from saved data.\"\"\"\n",
    "    # Convert string to Path if necessary\n",
    "    if isinstance(exp_dir, str):\n",
    "        exp_dir = Path(\"experiments\") / exp_dir\n",
    "    elif isinstance(exp_dir, Path):\n",
    "        exp_dir = Path(\"experiments\") / exp_dir.name\n",
    "    \n",
    "    exp_dir = exp_dir.absolute()\n",
    "    \n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "    print(f\"Looking for directory: {exp_dir}\")\n",
    "    \n",
    "    # Verify experiment directory exists\n",
    "    if not exp_dir.exists():\n",
    "        print(\"\\nContents of experiments directory:\")\n",
    "        try:\n",
    "            experiments_dir = Path(\"experiments\")\n",
    "            for item in experiments_dir.iterdir():\n",
    "                print(f\"  {item.name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error listing experiments directory: {e}\")\n",
    "        raise ValueError(f\"Experiment directory does not exist: {exp_dir}\")\n",
    "    \n",
    "    # Create seaborn plots directory\n",
    "    seaborn_dir = exp_dir / \"seaborn_plots\"\n",
    "    seaborn_dir.mkdir(exist_ok=True)\n",
    "    logging.info(f\"Created seaborn directory at: {seaborn_dir}\")\n",
    "    \n",
    "    # Verify data directory exists\n",
    "    data_dir = exp_dir / \"intermediate_data\"\n",
    "    if not data_dir.exists():\n",
    "        raise ValueError(f\"Data directory does not exist: {data_dir}\")\n",
    "    \n",
    "    # Get all metrics files\n",
    "    metrics_files = sorted(data_dir.glob(\"metrics_*.csv\"))\n",
    "    task_files = sorted(data_dir.glob(\"task_accuracies_*.csv\"))\n",
    "    \n",
    "    logging.info(f\"Found {len(metrics_files)} metrics files and {len(task_files)} task files\")\n",
    "    \n",
    "    if not metrics_files:\n",
    "        raise ValueError(f\"No metrics files found in {data_dir}\")\n",
    "    #######\n",
    "    # Combine all metrics data\n",
    "    all_metrics = []\n",
    "    for file in metrics_files:\n",
    "        df = pd.read_csv(file)\n",
    "        all_metrics.append(df)\n",
    "    metrics_df = pd.concat(all_metrics, ignore_index=True)\n",
    "    \n",
    "    # Create epoch bins for averaging, handling duplicates\n",
    "    try:\n",
    "        metrics_df['epoch_bin'] = pd.qcut(metrics_df['flops'], \n",
    "                                        q=len(metrics_df)//epoch_window, \n",
    "                                        labels=False,\n",
    "                                        duplicates='drop')\n",
    "    except ValueError:\n",
    "        # If qcut fails, use regular cut with logarithmic bins\n",
    "        n_bins = len(metrics_df)//epoch_window\n",
    "        metrics_df['epoch_bin'] = pd.cut(np.log10(metrics_df['flops']),\n",
    "                                       bins=n_bins,\n",
    "                                       labels=False)\n",
    "    \n",
    "    # Task - specific accuracy data\n",
    "    all_task_data = []\n",
    "    for file in task_files:\n",
    "        df = pd.read_csv(file)\n",
    "        task_cols = [col for col in df.columns if 'task' in col]\n",
    "        for i in range(0, len(task_cols), 2):\n",
    "            flops_col = task_cols[i]\n",
    "            acc_col = task_cols[i+1]\n",
    "            task_num = flops_col.split('_')[1]\n",
    "            \n",
    "            task_df = pd.DataFrame({\n",
    "                'flops': df[flops_col],\n",
    "                'accuracy': df[acc_col],\n",
    "                'task': f'Task {task_num}'\n",
    "            })\n",
    "            all_task_data.append(task_df)\n",
    "    \n",
    "    task_df = pd.concat(all_task_data, ignore_index=True)\n",
    "    try:\n",
    "        task_df['epoch_bin'] = pd.qcut(task_df['flops'], \n",
    "                                     q=len(task_df)//epoch_window, \n",
    "                                     labels=False,\n",
    "                                     duplicates='drop')\n",
    "    except ValueError:\n",
    "        n_bins = len(task_df)//epoch_window\n",
    "        task_df['epoch_bin'] = pd.cut(np.log10(task_df['flops']),\n",
    "                                    bins=n_bins,\n",
    "                                    labels=False)\n",
    "        ########\n",
    "\n",
    "    # Set up the plotting style\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_palette(\"husl\")\n",
    "    \n",
    "    # Create three subplots\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 6))\n",
    "    \n",
    "    # 1. Loss plot\n",
    "    sns.lineplot(data=metrics_df, \n",
    "                x='flops', \n",
    "                y='loss',\n",
    "                errorbar=('ci', confidence_interval),\n",
    "                ax=ax1)\n",
    "    ax1.set_xscale('log')\n",
    "    ax1.set_yscale('log')\n",
    "    ax1.set_title('Training Loss vs FLOPs')\n",
    "    ax1.set_xlabel('FLOPs')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    \n",
    "    # 2. Accuracy plot\n",
    "    sns.lineplot(data=metrics_df, \n",
    "                x='flops', \n",
    "                y='accuracy',\n",
    "                errorbar=('ci', confidence_interval),\n",
    "                ax=ax2)\n",
    "    ax2.set_xscale('log')\n",
    "    ax2.set_title('Overall Accuracy vs FLOPs')\n",
    "    ax2.set_xlabel('FLOPs')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    \n",
    "    sns.lineplot(data=task_df, \n",
    "                x='flops', \n",
    "                y='accuracy',\n",
    "                hue='task',\n",
    "                errorbar=('ci', confidence_interval),\n",
    "                ax=ax3)\n",
    "    ax3.set_xscale('log')\n",
    "    ax3.set_title('Task-Specific Accuracy vs FLOPs')\n",
    "    ax3.set_xlabel('FLOPs')\n",
    "    ax3.set_ylabel('Accuracy')\n",
    "    \n",
    "    # Adjust layout and save\n",
    "    plt.tight_layout()\n",
    "    plot_path = seaborn_dir / f\"seaborn_summary_window{epoch_window}_ci{confidence_interval}.png\"\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()\n",
    "    \n",
    "    # Also create separate plots for each metric with error bands\n",
    "    metrics = ['loss', 'accuracy']\n",
    "    for metric in metrics:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.lineplot(data=metrics_df, \n",
    "                    x='flops', \n",
    "                    y=metric,\n",
    "                    errorbar=('ci', confidence_interval))\n",
    "        plt.xscale('log')\n",
    "        if metric == 'loss':\n",
    "            plt.yscale('log')\n",
    "        plt.title(f'{metric.capitalize()} vs FLOPs')\n",
    "        plt.xlabel('FLOPs')\n",
    "        plt.ylabel(metric.capitalize())\n",
    "        plt.tight_layout()\n",
    "        plot_path = seaborn_dir / f\"seaborn_{metric}_window{epoch_window}_ci{confidence_interval}.png\"\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "    \n",
    "    # Create task-specific plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(data=task_df, \n",
    "                x='flops', \n",
    "                y='accuracy',\n",
    "                hue='task',\n",
    "                errorbar=('ci', confidence_interval))\n",
    "    plt.xscale('log')\n",
    "    plt.title('Task-Specific Accuracy vs FLOPs')\n",
    "    plt.xlabel('FLOPs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.tight_layout()\n",
    "    plot_path = seaborn_dir / f\"seaborn_task_accuracy_window{epoch_window}_ci{confidence_interval}.png\"\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()\n",
    "\n",
    "    logging.info(f\"Created seaborn plots in {seaborn_dir}\")\n",
    "\n",
    "#create_seaborn_plots(Path('parity_scaling_flops_1e+10__20250108_000607_v1'))\n",
    "exp_dir = Path('/experiments/parity_scaling_flops_1e+12__20250108_005311_v1')\n",
    "# When calling the function\n",
    "#print(f\"Original exp_dir: {exp_dir}\")\n",
    "#print(f\"Absolute exp_dir: {exp_dir.resolve()}\")\n",
    "create_seaborn_plots(exp_dir.resolve(), epoch_window = 100) # larger epoch windows result in slowdown\n",
    "#create_seaborn_plots(Path('workspace/project/experiments/parity_scaling_flops_1e+10__20250108_000607_v1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plots_from_saved_data(exp_dir: str | Path, model_configs=MODEL_CONFIGS):\n",
    "    \"\"\"\n",
    "    Create plots from saved data in experiment directory.\n",
    "    \n",
    "    Args:\n",
    "        exp_dir: Path to experiment directory (can be string or Path)\n",
    "        model_configs: List of model configurations (defaults to MODEL_CONFIGS)\n",
    "    \"\"\"\n",
    "    # Convert string to Path if necessary\n",
    "    if isinstance(exp_dir, str):\n",
    "        exp_dir = Path(\"experiments\") / exp_dir\n",
    "    elif isinstance(exp_dir, Path):\n",
    "        exp_dir = Path(\"experiments\") / exp_dir.name\n",
    "    \n",
    "    exp_dir = exp_dir.absolute()\n",
    "    print(f\"Looking for data in: {exp_dir}\")\n",
    "    \n",
    "    # Create plots directory if it doesn't exist\n",
    "    plots_dir = exp_dir / \"analysis_plots\"\n",
    "    plots_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Get all data files for each model configuration\n",
    "    all_loss_data = []\n",
    "    all_accuracy_data = []\n",
    "    all_task_accuracy_data = []\n",
    "    \n",
    "    for config in model_configs:\n",
    "        config_str = f\"{config['num_layers']}x{config['hidden_size']}\"\n",
    "        data_dir = exp_dir / \"intermediate_data\" / config_str\n",
    "        \n",
    "        # Read metrics data\n",
    "        metrics_files = sorted(data_dir.glob(\"metrics_*.csv\"))\n",
    "        if not metrics_files:\n",
    "            print(f\"No metrics files found for configuration {config_str}\")\n",
    "            continue\n",
    "            \n",
    "        # Combine all metrics data for this configuration\n",
    "        config_metrics = []\n",
    "        for file in metrics_files:\n",
    "            df = pd.read_csv(file)\n",
    "            config_metrics.append(df)\n",
    "        \n",
    "        if config_metrics:\n",
    "            metrics_df = pd.concat(config_metrics, ignore_index=True)\n",
    "            # Sort by FLOPs to ensure correct plotting\n",
    "            metrics_df = metrics_df.sort_values('flops')\n",
    "            \n",
    "            all_loss_data.append((metrics_df['flops'].values, metrics_df['loss'].values))\n",
    "            all_accuracy_data.append((metrics_df['flops'].values, metrics_df['accuracy'].values))\n",
    "            \n",
    "            # Read task-specific data\n",
    "            task_files = sorted(data_dir.glob(\"task_accuracies_*.csv\"))\n",
    "            task_data_dict = {}\n",
    "            \n",
    "            for file in task_files:\n",
    "                df = pd.read_csv(file)\n",
    "                for task_idx in range(PARAMS['n_tasks']):\n",
    "                    flops_col = f'task_{task_idx}_flops'\n",
    "                    acc_col = f'task_{task_idx}_accuracy'\n",
    "                    if flops_col in df.columns and acc_col in df.columns:\n",
    "                        if task_idx not in task_data_dict:\n",
    "                            task_data_dict[task_idx] = []\n",
    "                        task_data_dict[task_idx].extend(list(zip(df[flops_col], df[acc_col])))\n",
    "            \n",
    "            # Sort task data by FLOPs\n",
    "            for task_idx in task_data_dict:\n",
    "                task_data_dict[task_idx].sort(key=lambda x: x[0])\n",
    "            \n",
    "            all_task_accuracy_data.append(task_data_dict)\n",
    "    \n",
    "    # Create plots\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(1, 3, 1)\n",
    "    for i, config in enumerate(model_configs):\n",
    "        if i < len(all_loss_data):\n",
    "            flops, losses = all_loss_data[i]\n",
    "            plt.loglog(flops, losses, label=f'{config[\"num_layers\"]}x{config[\"hidden_size\"]}')\n",
    "    plt.xlabel('Cumulative FLOPs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss vs FLOPs')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot overall accuracy\n",
    "    plt.subplot(1, 3, 2)\n",
    "    for i, config in enumerate(model_configs):\n",
    "        if i < len(all_accuracy_data):\n",
    "            flops, accuracies = all_accuracy_data[i]\n",
    "            plt.semilogx(flops, accuracies, label=f'{config[\"num_layers\"]}x{config[\"hidden_size\"]}')\n",
    "    plt.xlabel('Cumulative FLOPs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy vs FLOPs')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot task-specific accuracies\n",
    "    plt.subplot(1, 3, 3)\n",
    "    for i, config in enumerate(model_configs):\n",
    "        if i < len(all_task_accuracy_data):\n",
    "            task_dict = all_task_accuracy_data[i]\n",
    "            for task_idx in task_dict:\n",
    "                flops, accuracies = zip(*task_dict[task_idx])\n",
    "                plt.semilogx(flops, accuracies, \n",
    "                           label=f'Task {task_idx+1} - {config[\"num_layers\"]}x{config[\"hidden_size\"]}')\n",
    "    plt.xlabel('Cumulative FLOPs')\n",
    "    plt.ylabel('Task-specific Accuracy')\n",
    "    plt.title('Task-specific Accuracies vs FLOPs')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plot_path = plots_dir / \"analysis_comparison.png\"\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Saved analysis plot to {plot_path}\")\n",
    "\n",
    "# Example usage:\n",
    "exp_dir = Path('/experiments/parity_scaling_flops_1e+12__20250108_005311_v1')\n",
    "# When calling the function\n",
    "#print(f\"Original exp_dir: {exp_dir}\")\n",
    "#print(f\"Absolute exp_dir: {exp_dir.resolve()}\")\n",
    "create_plots_from_saved_data(exp_dir.resolve()) # untested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
