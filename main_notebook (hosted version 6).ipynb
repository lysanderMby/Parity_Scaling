{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of test of parity scaling laws in Jupyter notebook.\n",
    "\n",
    "The code contained here is very similar to that in the rest of the repo, but is not guarenteed to be identical.\n",
    "\n",
    "This notebook is included for ease of use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (1.26.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (4.66.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.11/site-packages (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.11/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /opt/conda/lib/python3.11/site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/conda/lib/python3.11/site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /opt/conda/lib/python3.11/site-packages (from seaborn) (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (2.4.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "Requirement already satisfied: pathlib in /opt/conda/lib/python3.11/site-packages (1.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Package imports\n",
    "\n",
    "# pip install if necessary\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install tqdm\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install torch\n",
    "!pip install pathlib\n",
    "\n",
    "# Standard library imports (no pip install needed)\n",
    "import logging  # built-in module\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "# Third part imports (pip install may be required. See requirements.txt if looking to run the rest of the python project)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime\n",
    "import os\n",
    "from typing import Tuple, Dict # if used, this should be moved to the import section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# Parameters\n",
    "PARAMS = {\n",
    "    'n_tasks': 1, # number of unique tasks being trained over\n",
    "    'len_taskcode': 4, # number of bits in the task code\n",
    "    'num_checks': 5, # number of bits in the message that are used to determine the output\n",
    "    'len_message': 16, # number of bits in the message\n",
    "    'num_samples': 1000, # number of samples to generate for each task, per 'epoch' (in the infinite data regime, terminology is slightly abused)\n",
    "    'input_size': 20,  # len_taskcode + len_message. Used for model initialisation\n",
    "    'output_size': 1, # output size of the model. 1 for binary classification. Do not change\n",
    "    'learning_rate': 0.005, # constant learning rate. Could introduce a scheduler?\n",
    "    'batch_size': 32, # batch size used in training. Will be the same throughout a run\n",
    "    'flop_budget': 1e12, # total number of estimated flops expended per training run\n",
    "    'task_sample_freq': 1e12/1e3,  # the rate at which performance is evaluated. Can give a big performance hit\n",
    "    'plot_freq': 1e12/20,  # Frequency of created plots. Note that this is also the frequency at which data is saved \n",
    "    # a large plot_freq can result in significant memory consumption\n",
    "    'samples_per_task': 100 # number of samples to generate for each task in evaluation\n",
    "    # Note: samples_per_task is not very relevant when there is only one task, as it reproduces earlier calculations exactly\n",
    "}\n",
    "\n",
    "# Define a range of model configurations\n",
    "model_configs = [\n",
    "    {\"num_layers\": 2, \"hidden_size\": 8},\n",
    "    {\"num_layers\": 4, \"hidden_size\": 16},\n",
    "    {\"num_layers\": 6, \"hidden_size\": 32},\n",
    "    {\"num_layers\": 8, \"hidden_size\": 64},\n",
    "    {\"num_layers\": 10, \"hidden_size\": 128},\n",
    "    {\"num_layers\": 12, \"hidden_size\": 256},\n",
    "    {\"num_layers\": 14, \"hidden_size\": 512} \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "    \n",
    "def generate_random_binary_string(length):\n",
    "    # Random binary string of length 'length'\n",
    "    return ''.join(random.choice(['0', '1']) for _ in range(length))\n",
    "\n",
    "def generate_dict(n_tasks, len_taskcode, num_checks, len_message):\n",
    "    # Generate the task codes and their associated check bits\n",
    "    unique_strings = set()\n",
    "    tasks_dict = {}\n",
    "    while len(unique_strings) < n_tasks:\n",
    "        binary_string = generate_random_binary_string(len_taskcode)\n",
    "        if binary_string not in unique_strings:\n",
    "            unique_strings.add(binary_string)\n",
    "            integer_list = [random.randint(0, len_message-1) for _ in range(num_checks)]\n",
    "            tasks_dict[binary_string] = integer_list\n",
    "    return tasks_dict\n",
    "\n",
    "def generate_dataset(tasks_dict, num_samples, len_taskcode, len_message):\n",
    "    # Generate a dataset of num_samples samples using tasks specified in tasks_dict\n",
    "    data = np.zeros((num_samples, len_taskcode + len_message))\n",
    "    value = np.zeros(num_samples)\n",
    "    for i in range(num_samples):\n",
    "        rand_task = np.random.choice(list(tasks_dict))\n",
    "        rand_checkbits = tasks_dict[rand_task]\n",
    "        message = generate_random_binary_string(len_message)\n",
    "        parity_bit = sum(int(message[j]) for j in rand_checkbits) % 2\n",
    "        data[i] = np.concatenate((np.array(list(rand_task)), np.array(list(message))))\n",
    "        value[i] = parity_bit\n",
    "    return [data, value]\n",
    "\n",
    "def generate_dataset_for_task(task_code, tasks_dict, num_samples, len_taskcode, len_message):\n",
    "    # Generate a dataset of num_samples samples for a specific task\n",
    "    # Used primarily for evaluation. Very limited performance improvement from generate_dataset\n",
    "    data = np.zeros((num_samples, len_taskcode + len_message))\n",
    "    value = np.zeros(num_samples)\n",
    "    rand_checkbits = tasks_dict[task_code]\n",
    "    for i in range(num_samples):\n",
    "        message = generate_random_binary_string(len_message)\n",
    "        parity_bit = sum(int(message[j]) for j in rand_checkbits) % 2\n",
    "        data[i] = np.concatenate((np.array(list(task_code)), np.array(list(message))))\n",
    "        value[i] = parity_bit\n",
    "    return [data, value]\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, device):\n",
    "        # Convert to numpy first for efficiency\n",
    "        data_np = dataframe.iloc[:, :-1].values\n",
    "        target_np = dataframe.iloc[:, -1].values\n",
    "        \n",
    "        # Single transfer to device. IO-aware for greater efficiency\n",
    "        self.data = torch.from_numpy(data_np).float().to(device)\n",
    "        self.target = torch.from_numpy(target_np).float().to(device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.target[idx]\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_layers, hidden_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(nn.Linear(input_size, hidden_size))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "            self.layers.append(nn.BatchNorm1d(hidden_size))\n",
    "        self.layers.append(nn.Linear(hidden_size, output_size))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for i, layer in enumerate(self.layers[:-1]):\n",
    "            if i == 0:\n",
    "                x = F.relu(layer(x))\n",
    "            else:\n",
    "                x = layer(x)\n",
    "                if i % 2 == 0:\n",
    "                    x = F.relu(x)\n",
    "        x = self.layers[-1](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot intermediate progress\n",
    "\n",
    "def plot_progress(loss_data, accuracy_data, task_accuracy_data, cumulative_flops, exp_dir, model_config):\n",
    "    \"\"\"\n",
    "    Plot and save training progress.\n",
    "    \n",
    "    Args:\n",
    "        loss_data: List of tuples (flops, loss)\n",
    "        accuracy_data: List of tuples (flops, accuracy)\n",
    "        task_accuracy_data: Dict of lists of tuples (flops, accuracy) for each task\n",
    "        cumulative_flops: Current total FLOPs\n",
    "        exp_dir: Path to experiment directory\n",
    "        model_config: Dictionary containing model configuration\n",
    "    \"\"\"\n",
    "    # Create model-specific subdirectories\n",
    "    config_str = f\"{model_config['num_layers']}x{model_config['hidden_size']}\"\n",
    "    plots_dir = exp_dir / \"intermediate_plots\" / config_str\n",
    "    data_dir = exp_dir / \"intermediate_data\" / config_str\n",
    "    plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "    data_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Create figure with multiple subplots\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Plot loss\n",
    "    flops_loss, losses = zip(*loss_data)\n",
    "    ax1.plot(flops_loss, losses)\n",
    "    ax1.set_xlabel('FLOPs')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title(f'Training Loss vs FLOPs ({config_str})')\n",
    "    ax1.set_xscale('log')\n",
    "    ax1.set_yscale('log')\n",
    "    \n",
    "    # Plot overall accuracy\n",
    "    flops_acc, accuracies = zip(*accuracy_data)\n",
    "    ax2.plot(flops_acc, accuracies)\n",
    "    ax2.set_xlabel('FLOPs')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_title(f'Overall Accuracy vs FLOPs ({config_str})')\n",
    "    ax2.set_xscale('log')\n",
    "    \n",
    "    # Plot task-specific accuracies\n",
    "    for task_idx, task_data in task_accuracy_data.items():\n",
    "        if task_data:  # Check if there's data for this task\n",
    "            flops_task, task_accuracies = zip(*task_data)\n",
    "            ax3.plot(flops_task, task_accuracies, label=f'Task {task_idx}')\n",
    "    ax3.set_xlabel('FLOPs')\n",
    "    ax3.set_ylabel('Accuracy')\n",
    "    ax3.set_title(f'Task-Specific Accuracy vs FLOPs ({config_str})')\n",
    "    ax3.set_xscale('log')\n",
    "    ax3.legend()\n",
    "    \n",
    "    # Adjust layout and save\n",
    "    plt.tight_layout()\n",
    "    plot_path = plots_dir / f\"progress_{cumulative_flops:.2e}_flops.png\"\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()\n",
    "    \n",
    "    # Log the plot creation\n",
    "    logging.info(f\"Saved progress plot for {config_str} at {cumulative_flops:.2e} FLOPs to {plot_path}\")\n",
    "    \n",
    "    # Save the data as CSV\n",
    "    df_metrics = pd.DataFrame({\n",
    "        'flops': flops_loss,\n",
    "        'loss': losses,\n",
    "        'accuracy': accuracies,\n",
    "        'model_config': config_str\n",
    "    })\n",
    "    df_metrics.to_csv(data_dir / f\"metrics_{cumulative_flops:.2e}_flops.csv\", index=False)\n",
    "    \n",
    "    # Save task-specific accuracy data\n",
    "    task_data_dict = {\n",
    "        'model_config': config_str,\n",
    "        'flops': cumulative_flops\n",
    "    }\n",
    "    for task_idx, task_data in task_accuracy_data.items():\n",
    "        if task_data:\n",
    "            flops_task, task_accuracies = zip(*task_data)\n",
    "            task_data_dict[f'task_{task_idx}_flops'] = flops_task\n",
    "            task_data_dict[f'task_{task_idx}_accuracy'] = task_accuracies\n",
    "    \n",
    "    df_tasks = pd.DataFrame(task_data_dict)\n",
    "    df_tasks.to_csv(data_dir / f\"task_accuracies_{cumulative_flops:.2e}_flops.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main plot\n",
    "\n",
    "def main_plot(all_results, exp_dir):\n",
    "    \"\"\"\n",
    "    Create final plots comparing all model configurations.\n",
    "    \n",
    "    Args:\n",
    "        all_results: List of dictionaries containing results for each model config\n",
    "        exp_dir: Path to experiment directory\n",
    "    \"\"\"\n",
    "    # Extract data from results\n",
    "    all_loss_data = []\n",
    "    all_accuracy_data = []\n",
    "    all_task_accuracy_data = []\n",
    "    all_flops = []\n",
    "    \n",
    "    for result in all_results:\n",
    "        all_loss_data.append(result['loss_data'])\n",
    "        all_accuracy_data.append(result['accuracy_data'])\n",
    "        all_task_accuracy_data.append(result['task_accuracy_data'])\n",
    "        all_flops.append(result['cumulative_flops'])\n",
    "\n",
    "    # Create final plots\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(1, 3, 1)\n",
    "    for i, config in enumerate(model_configs):\n",
    "        flops, losses = zip(*all_loss_data[i])\n",
    "        plt.loglog(flops, losses, label=f'{config[\"num_layers\"]}x{config[\"hidden_size\"]}')\n",
    "    plt.xlabel('Cumulative FLOPs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss vs FLOPs')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot overall accuracy\n",
    "    plt.subplot(1, 3, 2)\n",
    "    for i, config in enumerate(model_configs):\n",
    "        flops, accuracies = zip(*all_accuracy_data[i])\n",
    "        plt.semilogx(flops, accuracies, label=f'{config[\"num_layers\"]}x{config[\"hidden_size\"]}')\n",
    "    plt.xlabel('Cumulative FLOPs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy vs FLOPs')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot task-specific accuracies\n",
    "    plt.subplot(1, 3, 3)\n",
    "    for i, config in enumerate(model_configs):\n",
    "        for task in range(PARAMS['n_tasks']):\n",
    "            flops, accuracies = zip(*all_task_accuracy_data[i][task])\n",
    "            plt.semilogx(flops, accuracies, \n",
    "                        label=f'Task {task+1} - {config[\"num_layers\"]}x{config[\"hidden_size\"]}')\n",
    "    plt.xlabel('Cumulative FLOPs')\n",
    "    plt.ylabel('Task-specific Accuracy')\n",
    "    plt.title('Task-specific Accuracies vs FLOPs')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plot_path = exp_dir / \"final_comparison.png\"\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()\n",
    "    \n",
    "    logging.info(f\"Saved final comparison plot to {plot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count FLOPs\n",
    "\n",
    "# No longer in use. fvcore seems to have given unreliable results, although this may down to my quite simplistic counting of flops\n",
    "#def count_flops_fvcore(model, input_size):\n",
    "#    input_tensor = torch.randn(2, input_size)\n",
    "#    flops = FlopCountAnalysis(model, input_tensor)\n",
    "#    return flops.total() // 2\n",
    "\n",
    "class FlopCounter:\n",
    "    def __init__(self, model: nn.Module, input_size: int, batch_size: int):\n",
    "        self.model = model\n",
    "        self.input_size = input_size\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def count_linear_flops(self, in_features: int, out_features: int) -> Dict[str, int]:\n",
    "        \"\"\"\n",
    "        Count FLOPs for linear layer operations.\n",
    "        Forward: Each output element requires in_features multiplications and in_features-1 additions\n",
    "        Backward: Requires computing gradients for weights, biases, and input\n",
    "        \"\"\"\n",
    "        forward_flops = self.batch_size * out_features * (2 * in_features - 1)  # mult-add pairs\n",
    "        \n",
    "        # Backward pass FLOPs:\n",
    "        # 1. dL/dW computation: batch_size * in_features * out_features * 2\n",
    "        # 2. dL/db computation: batch_size * out_features\n",
    "        # 3. dL/dx computation: batch_size * in_features * out_features * 2\n",
    "        backward_flops = (\n",
    "            self.batch_size * in_features * out_features * 2 +  # dL/dW\n",
    "            self.batch_size * out_features +                    # dL/db\n",
    "            self.batch_size * in_features * out_features * 2    # dL/dx\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"forward\": forward_flops,\n",
    "            \"backward\": backward_flops\n",
    "        }\n",
    "    \n",
    "    def count_batch_norm_flops(self, num_features: int) -> Dict[str, int]:\n",
    "        \"\"\"\n",
    "        Count FLOPs for batch normalization operations.\n",
    "        Forward: Computing mean, variance, normalized values, and scaling\n",
    "        Backward: Computing gradients for gamma, beta, and input\n",
    "        \"\"\"\n",
    "        # Forward pass operations per feature:\n",
    "        # 1. Mean calculation: batch_size additions\n",
    "        # 2. Variance calculation: batch_size multiplications and additions\n",
    "        # 3. Normalization: 4 operations per element (subtract mean, divide by std)\n",
    "        # 4. Scale and shift: 2 operations per element\n",
    "        forward_flops = self.batch_size * num_features * (7)\n",
    "        \n",
    "        # Backward pass operations:\n",
    "        # 1. Gradients for gamma and beta: batch_size additions per feature\n",
    "        # 2. Gradients for input: ~8 operations per element\n",
    "        backward_flops = self.batch_size * num_features * 10\n",
    "        \n",
    "        return {\n",
    "            \"forward\": forward_flops,\n",
    "            \"backward\": backward_flops\n",
    "        }\n",
    "    \n",
    "    def count_relu_flops(self, num_elements: int) -> Dict[str, int]:\n",
    "        \"\"\"\n",
    "        Count FLOPs for ReLU activation.\n",
    "        Forward: One comparison per element\n",
    "        Backward: One multiplication per element (gradient is 0 or 1)\n",
    "        \"\"\"\n",
    "        forward_flops = num_elements  # One comparison per element\n",
    "        backward_flops = num_elements  # One multiplication per element\n",
    "        \n",
    "        return {\n",
    "            \"forward\": forward_flops,\n",
    "            \"backward\": backward_flops\n",
    "        }\n",
    "    \n",
    "    def calculate_total_flops(self) -> Tuple[int, int]:\n",
    "        \"\"\"\n",
    "        Calculate total FLOPs for both forward and backward passes through the entire model.\n",
    "        Returns tuple of (forward_flops, backward_flops)\n",
    "        \"\"\"\n",
    "        total_forward_flops = 0\n",
    "        total_backward_flops = 0\n",
    "        \n",
    "        current_size = self.input_size\n",
    "        \n",
    "        for layer in self.model.layers:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                flops = self.count_linear_flops(layer.in_features, layer.out_features)\n",
    "                total_forward_flops += flops[\"forward\"]\n",
    "                total_backward_flops += flops[\"backward\"]\n",
    "                current_size = layer.out_features\n",
    "                \n",
    "            elif isinstance(layer, nn.BatchNorm1d):\n",
    "                flops = self.count_batch_norm_flops(current_size)\n",
    "                total_forward_flops += flops[\"forward\"]\n",
    "                total_backward_flops += flops[\"backward\"]\n",
    "                \n",
    "            # Count ReLU FLOPs after linear layers (except the last one)\n",
    "            if isinstance(layer, nn.Linear) and layer != self.model.layers[-1]:\n",
    "                flops = self.count_relu_flops(self.batch_size * current_size)\n",
    "                total_forward_flops += flops[\"forward\"]\n",
    "                total_backward_flops += flops[\"backward\"]\n",
    "        \n",
    "        return total_forward_flops, total_backward_flops\n",
    "\n",
    "def get_flops_per_pass(model: nn.Module, input_size: int, batch_size: int) -> Tuple[int, int]:\n",
    "    \"\"\"\n",
    "    Wrapper function to get FLOPs per forward and backward pass.\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch neural network model\n",
    "        input_size: Size of input features\n",
    "        batch_size: Batch size used in training\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (forward_flops, backward_flops)\n",
    "    \"\"\"\n",
    "    counter = FlopCounter(model, input_size, batch_size)\n",
    "    return counter.calculate_total_flops()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Managing saving of files\n",
    "\n",
    "def create_versioned_directory(base_dir: Path, name: str) -> Path:\n",
    "    \"\"\"\n",
    "    Create a versioned directory to avoid overwriting existing experiments.\n",
    "    \n",
    "    Args:\n",
    "        base_dir: Base directory for experiments\n",
    "        name: Base name for the experiment directory\n",
    "        \n",
    "    Returns:\n",
    "        Path: Path to the created directory\n",
    "    \"\"\"\n",
    "    base_dir.mkdir(exist_ok=True)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    version = 1\n",
    "    \n",
    "    while True:\n",
    "        versioned_name = f\"{name}__{timestamp}_v{version}\"\n",
    "        dir_path = base_dir / versioned_name\n",
    "        if not dir_path.exists():\n",
    "            dir_path.mkdir()\n",
    "            return dir_path\n",
    "        version += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "\n",
    "# This function has been significantly modified to incorporate the new count FLOPs function\n",
    "# There may be bugs down the line related to how data is collected and displayed. This should be more thoroughly debugged\n",
    "\n",
    "def train_and_evaluate(model, params, tasks_dict, exp_dir, model_config):\n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Move model to device\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Initialize criterion and optimizer\n",
    "    criterion = nn.BCEWithLogitsLoss() # Identical to BCE, except for application of sigmoid to the outputs. Gives smoother loss\n",
    "    optimizer = optim.SGD(model.parameters(), lr=params['learning_rate'])\n",
    "    \n",
    "    # Initialize FlopCounter\n",
    "    flop_counter = FlopCounter(model, input_size=params['input_size'], batch_size=params['batch_size'])\n",
    "    forward_flops, backward_flops = flop_counter.calculate_total_flops()\n",
    "    \n",
    "    loss_data = []\n",
    "    accuracy_data = []\n",
    "    task_accuracy_data = {i: [] for i in range(params['n_tasks'])}\n",
    "    cumulative_flops = 0\n",
    "    epoch = 0\n",
    "    last_task_sample = 0\n",
    "    last_plot = 0\n",
    "\n",
    "    print_rate = params['flop_budget'] / 1e1 # prints only when the FLOP budget is reached\n",
    "    disp_flops = 0\n",
    "    \n",
    "    while cumulative_flops < params['flop_budget']:\n",
    "        if cumulative_flops - print_rate > disp_flops:\n",
    "            print(f'cumulative_flops: {cumulative_flops} - flop_budget: {params[\"flop_budget\"]} - Percentage completion: {(cumulative_flops/params[\"flop_budget\"])*100:.2f}%')\n",
    "            disp_flops = cumulative_flops\n",
    "            \n",
    "        epoch += 1\n",
    "        [data, value] = generate_dataset(tasks_dict, params['num_samples'], \n",
    "                                       params['len_taskcode'], params['len_message'])\n",
    "        df = pd.DataFrame(np.concatenate((data, value.reshape(-1, 1)), axis=1))\n",
    "        \n",
    "        dataset = CustomDataset(df, device)\n",
    "        data_loader = DataLoader(dataset, batch_size=params['batch_size'], shuffle=True)\n",
    "        \n",
    "        epoch_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        model.train()\n",
    "\n",
    "        for inputs, labels in data_loader:\n",
    "            outputs = model(inputs)\n",
    "            batch_loss = criterion(outputs, labels.unsqueeze(1))\n",
    "            predictions = (outputs >= 0.5).squeeze().long()\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += batch_loss.item() * inputs.size(0)\n",
    "            \n",
    "            # Calculate FLOPs\n",
    "            batch_flops = forward_flops + backward_flops\n",
    "            cumulative_flops += batch_flops\n",
    "\n",
    "        avg_loss = epoch_loss / len(dataset)\n",
    "        avg_accuracy = correct / total\n",
    "\n",
    "        loss_data.append((cumulative_flops, avg_loss))\n",
    "        accuracy_data.append((cumulative_flops, avg_accuracy))\n",
    "        \n",
    "        # Task-specific evaluation\n",
    "        if cumulative_flops - last_task_sample >= params['task_sample_freq'] or cumulative_flops >= params['flop_budget']:\n",
    "            last_task_sample = cumulative_flops\n",
    "            \n",
    "            for task_idx, task_code in enumerate(tasks_dict.keys()):\n",
    "                [data_per_task, value_per_task] = generate_dataset_for_task(\n",
    "                    task_code, tasks_dict, params['samples_per_task'],\n",
    "                    params['len_taskcode'], params['len_message']\n",
    "                )\n",
    "                df_per_task = pd.DataFrame(np.concatenate((data_per_task, value_per_task.reshape(-1, 1)), axis=1))\n",
    "                dataset_per_task = CustomDataset(df_per_task, device)\n",
    "                loader_per_task = DataLoader(dataset_per_task, batch_size=params['batch_size'], shuffle=True)\n",
    "                \n",
    "                model.eval()\n",
    "                task_correct = 0\n",
    "                task_total = 0\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    for inputs, labels in loader_per_task:\n",
    "                        outputs = model(inputs)\n",
    "                        predictions = (outputs >= 0.5).squeeze().long()\n",
    "                        task_correct += (predictions == labels).sum().item()\n",
    "                        task_total += labels.size(0)\n",
    "                        cumulative_flops += forward_flops\n",
    "                        \n",
    "                task_accuracy = task_correct / task_total\n",
    "                task_accuracy_data[task_idx].append((cumulative_flops, task_accuracy))\n",
    "\n",
    "        if cumulative_flops - last_plot >= params['plot_freq']:\n",
    "            last_plot = cumulative_flops\n",
    "            plot_progress(loss_data, accuracy_data, task_accuracy_data, cumulative_flops, exp_dir, model_config)\n",
    "\n",
    "    return { # loss_data, accuracy_data, task_accuracy_data, cumulative_flops\n",
    "        'loss_data': loss_data,\n",
    "        'accuracy_data': accuracy_data,\n",
    "        'task_accuracy_data': task_accuracy_data,\n",
    "        'cumulative_flops': cumulative_flops,\n",
    "        'model_config': model_config\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Experiment directory: experiments/parity_scaling_flops_1e+12__20250108_232600_v1\n",
      "FLOP budget: 1000000000000.0\n",
      "Generated tasks dictionary with 1 tasks\n",
      "tasks_dict =  dict_items([('1111', [1, 11, 12, 13, 5])])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 2 layers and hidden size 8\n",
      "Using device: cuda\n",
      "cumulative_flops: 100000646784 - flop_budget: 1000000000000.0 - Percentage completion: 10.00%\n",
      "cumulative_flops: 200001336448 - flop_budget: 1000000000000.0 - Percentage completion: 20.00%\n",
      "cumulative_flops: 300002026112 - flop_budget: 1000000000000.0 - Percentage completion: 30.00%\n",
      "cumulative_flops: 400002715776 - flop_budget: 1000000000000.0 - Percentage completion: 40.00%\n",
      "cumulative_flops: 500003405440 - flop_budget: 1000000000000.0 - Percentage completion: 50.00%\n",
      "cumulative_flops: 600004095104 - flop_budget: 1000000000000.0 - Percentage completion: 60.00%\n",
      "cumulative_flops: 700004784768 - flop_budget: 1000000000000.0 - Percentage completion: 70.00%\n",
      "cumulative_flops: 800005474432 - flop_budget: 1000000000000.0 - Percentage completion: 80.00%\n",
      "cumulative_flops: 900006164096 - flop_budget: 1000000000000.0 - Percentage completion: 90.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:  14%|█▍        | 1/7 [14:56:27<89:38:47, 53787.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 4 layers and hidden size 16\n",
      "Using device: cuda\n",
      "cumulative_flops: 100001287808 - flop_budget: 1000000000000.0 - Percentage completion: 10.00%\n",
      "cumulative_flops: 200002821248 - flop_budget: 1000000000000.0 - Percentage completion: 20.00%\n",
      "cumulative_flops: 300004354688 - flop_budget: 1000000000000.0 - Percentage completion: 30.00%\n",
      "cumulative_flops: 400005642496 - flop_budget: 1000000000000.0 - Percentage completion: 40.00%\n",
      "cumulative_flops: 500007175936 - flop_budget: 1000000000000.0 - Percentage completion: 50.00%\n",
      "cumulative_flops: 600008709376 - flop_budget: 1000000000000.0 - Percentage completion: 60.00%\n",
      "cumulative_flops: 700009997184 - flop_budget: 1000000000000.0 - Percentage completion: 70.00%\n",
      "cumulative_flops: 800011530624 - flop_budget: 1000000000000.0 - Percentage completion: 80.00%\n",
      "cumulative_flops: 900013064064 - flop_budget: 1000000000000.0 - Percentage completion: 90.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:  29%|██▊       | 2/7 [19:11:48<43:16:40, 31160.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 6 layers and hidden size 32\n",
      "Using device: cuda\n",
      "cumulative_flops: 100014001920 - flop_budget: 1000000000000.0 - Percentage completion: 10.00%\n",
      "cumulative_flops: 200028003840 - flop_budget: 1000000000000.0 - Percentage completion: 20.00%\n",
      "cumulative_flops: 300042005760 - flop_budget: 1000000000000.0 - Percentage completion: 30.00%\n",
      "cumulative_flops: 400056007680 - flop_budget: 1000000000000.0 - Percentage completion: 40.01%\n",
      "cumulative_flops: 500070009600 - flop_budget: 1000000000000.0 - Percentage completion: 50.01%\n",
      "cumulative_flops: 600084011520 - flop_budget: 1000000000000.0 - Percentage completion: 60.01%\n",
      "cumulative_flops: 700098013440 - flop_budget: 1000000000000.0 - Percentage completion: 70.01%\n",
      "cumulative_flops: 800112015360 - flop_budget: 1000000000000.0 - Percentage completion: 80.01%\n",
      "cumulative_flops: 900126017280 - flop_budget: 1000000000000.0 - Percentage completion: 90.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:  43%|████▎     | 3/7 [20:14:03<20:42:29, 18637.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 8 layers and hidden size 64\n",
      "Using device: cuda\n",
      "cumulative_flops: 100136341120 - flop_budget: 1000000000000.0 - Percentage completion: 10.01%\n",
      "cumulative_flops: 200272682240 - flop_budget: 1000000000000.0 - Percentage completion: 20.03%\n",
      "cumulative_flops: 300416002816 - flop_budget: 1000000000000.0 - Percentage completion: 30.04%\n",
      "cumulative_flops: 400552343936 - flop_budget: 1000000000000.0 - Percentage completion: 40.06%\n",
      "cumulative_flops: 500688685056 - flop_budget: 1000000000000.0 - Percentage completion: 50.07%\n",
      "cumulative_flops: 600832005632 - flop_budget: 1000000000000.0 - Percentage completion: 60.08%\n",
      "cumulative_flops: 700968346752 - flop_budget: 1000000000000.0 - Percentage completion: 70.10%\n",
      "cumulative_flops: 801104687872 - flop_budget: 1000000000000.0 - Percentage completion: 80.11%\n",
      "cumulative_flops: 901248008448 - flop_budget: 1000000000000.0 - Percentage completion: 90.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:  57%|█████▋    | 4/7 [20:28:57<9:41:36, 11632.23s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 10 layers and hidden size 128\n",
      "Using device: cuda\n",
      "cumulative_flops: 100554040064 - flop_budget: 1000000000000.0 - Percentage completion: 10.06%\n",
      "cumulative_flops: 201143240064 - flop_budget: 1000000000000.0 - Percentage completion: 20.11%\n",
      "cumulative_flops: 301697280128 - flop_budget: 1000000000000.0 - Percentage completion: 30.17%\n",
      "cumulative_flops: 402286480128 - flop_budget: 1000000000000.0 - Percentage completion: 40.23%\n",
      "cumulative_flops: 502840520192 - flop_budget: 1000000000000.0 - Percentage completion: 50.28%\n",
      "cumulative_flops: 603429720192 - flop_budget: 1000000000000.0 - Percentage completion: 60.34%\n",
      "cumulative_flops: 703983760256 - flop_budget: 1000000000000.0 - Percentage completion: 70.40%\n",
      "cumulative_flops: 804572960256 - flop_budget: 1000000000000.0 - Percentage completion: 80.46%\n",
      "cumulative_flops: 905127000320 - flop_budget: 1000000000000.0 - Percentage completion: 90.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:  71%|███████▏  | 5/7 [20:32:36<4:10:33, 7516.63s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 12 layers and hidden size 256\n",
      "Using device: cuda\n",
      "cumulative_flops: 102752056320 - flop_budget: 1000000000000.0 - Percentage completion: 10.28%\n",
      "cumulative_flops: 205504112640 - flop_budget: 1000000000000.0 - Percentage completion: 20.55%\n",
      "cumulative_flops: 308256168960 - flop_budget: 1000000000000.0 - Percentage completion: 30.83%\n",
      "cumulative_flops: 411008225280 - flop_budget: 1000000000000.0 - Percentage completion: 41.10%\n",
      "cumulative_flops: 513760281600 - flop_budget: 1000000000000.0 - Percentage completion: 51.38%\n",
      "cumulative_flops: 616512337920 - flop_budget: 1000000000000.0 - Percentage completion: 61.65%\n",
      "cumulative_flops: 719264394240 - flop_budget: 1000000000000.0 - Percentage completion: 71.93%\n",
      "cumulative_flops: 822016450560 - flop_budget: 1000000000000.0 - Percentage completion: 82.20%\n",
      "cumulative_flops: 924768506880 - flop_budget: 1000000000000.0 - Percentage completion: 92.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:  86%|████████▌ | 6/7 [20:33:35<1:23:01, 4981.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 14 layers and hidden size 512\n",
      "Using device: cuda\n",
      "cumulative_flops: 101637815680 - flop_budget: 1000000000000.0 - Percentage completion: 10.16%\n",
      "cumulative_flops: 203275631360 - flop_budget: 1000000000000.0 - Percentage completion: 20.33%\n",
      "cumulative_flops: 304913447040 - flop_budget: 1000000000000.0 - Percentage completion: 30.49%\n",
      "cumulative_flops: 406551262720 - flop_budget: 1000000000000.0 - Percentage completion: 40.66%\n",
      "cumulative_flops: 508189078400 - flop_budget: 1000000000000.0 - Percentage completion: 50.82%\n",
      "cumulative_flops: 609826894080 - flop_budget: 1000000000000.0 - Percentage completion: 60.98%\n",
      "cumulative_flops: 711464709760 - flop_budget: 1000000000000.0 - Percentage completion: 71.15%\n",
      "cumulative_flops: 813102525440 - flop_budget: 1000000000000.0 - Percentage completion: 81.31%\n",
      "cumulative_flops: 914740341120 - flop_budget: 1000000000000.0 - Percentage completion: 91.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models: 100%|██████████| 7/7 [20:33:53<00:00, 10576.26s/it] \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'MODEL_CONFIGS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m     main_plot(all_results, exp_dir)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 48\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[9], line 45\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m     all_results\u001b[38;5;241m.\u001b[39mappend(results)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Create final plots\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m main_plot(all_results, exp_dir)\n",
      "Cell \u001b[0;32mIn[5], line 28\u001b[0m, in \u001b[0;36mmain_plot\u001b[0;34m(all_results, exp_dir)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Plot loss\u001b[39;00m\n\u001b[1;32m     27\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, config \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(MODEL_CONFIGS):\n\u001b[1;32m     29\u001b[0m     flops, losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mall_loss_data[i])\n\u001b[1;32m     30\u001b[0m     plt\u001b[38;5;241m.\u001b[39mloglog(flops, losses, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_layers\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mx\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_size\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MODEL_CONFIGS' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Main\n",
    "\n",
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Create experiment directory\n",
    "    exp_name = f\"parity_scaling_flops_{PARAMS['flop_budget']:.0e}\"\n",
    "    exp_dir = create_versioned_directory(Path(\"experiments\"), exp_name)\n",
    "    print(f\"Experiment directory: {exp_dir}\")\n",
    "\n",
    "    print(f\"FLOP budget: {PARAMS['flop_budget']}\")\n",
    "    \n",
    "    tasks_dict = generate_dict(\n",
    "        PARAMS['n_tasks'], \n",
    "        PARAMS['len_taskcode'], \n",
    "        PARAMS['num_checks'], \n",
    "        PARAMS['len_message']\n",
    "    )\n",
    "    print(f\"Generated tasks dictionary with {len(tasks_dict)} tasks\")\n",
    "    print(\"tasks_dict = \", tasks_dict.items())\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    # Add progress bar for model configurations\n",
    "    for config in tqdm(model_configs, desc=\"Training models\", position=0, leave=True):\n",
    "        print(f\"\\nTraining model with {config['num_layers']} layers and hidden size {config['hidden_size']}\")\n",
    "        model = NeuralNetwork(\n",
    "            PARAMS['input_size'], \n",
    "            PARAMS['output_size'], \n",
    "            config[\"num_layers\"], \n",
    "            config[\"hidden_size\"]\n",
    "        ).to(device)\n",
    "        # model, criterion, optimizer, flop_budget, tasks_dict\n",
    "        results = train_and_evaluate(\n",
    "            model=model,\n",
    "            params=PARAMS,\n",
    "            tasks_dict=tasks_dict,\n",
    "            exp_dir=exp_dir,\n",
    "            model_config=config\n",
    "        )\n",
    "        all_results.append(results)\n",
    "    \n",
    "    # Create final plots\n",
    "    main_plot(all_results, exp_dir)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_seaborn_plots(exp_dir: Path, epoch_window: int = 10, confidence_interval: float = 0.95):\n",
    "    \"\"\"Create seaborn plots from saved data across all model configurations.\"\"\"\n",
    "    # Set up logging\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "    \n",
    "    # Directory setup and validation\n",
    "    if isinstance(exp_dir, str):\n",
    "        exp_dir = Path(\"experiments\") / exp_dir\n",
    "    elif isinstance(exp_dir, Path):\n",
    "        exp_dir = Path(\"experiments\") / exp_dir.name\n",
    "    \n",
    "    exp_dir = exp_dir.absolute()\n",
    "    logger.info(f\"Looking for data in: {exp_dir}\")\n",
    "    \n",
    "    # Create seaborn plots directory\n",
    "    seaborn_dir = exp_dir / \"seaborn_plots\"\n",
    "    seaborn_dir.mkdir(exist_ok=True)\n",
    "    logger.info(f\"Created seaborn plots directory: {seaborn_dir}\")\n",
    "    \n",
    "    # Initialize lists to store all data\n",
    "    all_metrics = []\n",
    "    all_task_data = []\n",
    "    \n",
    "    # Iterate through model configuration directories\n",
    "    data_dir = exp_dir / \"intermediate_data\"\n",
    "    model_dirs = list(data_dir.glob(\"*x*\"))\n",
    "    logger.info(f\"Found {len(model_dirs)} model configuration directories\")\n",
    "    \n",
    "    for model_dir in model_dirs:\n",
    "        config_str = model_dir.name\n",
    "        logger.info(f\"Processing data for model configuration: {config_str}\")\n",
    "        \n",
    "        # Get metrics files for this configuration\n",
    "        metrics_files = sorted(model_dir.glob(\"metrics_*.csv\"))\n",
    "        logger.info(f\"Found {len(metrics_files)} metrics files for {config_str}\")\n",
    "        \n",
    "        for file in metrics_files:\n",
    "            try:\n",
    "                df = pd.read_csv(file)\n",
    "                df['model_config'] = config_str\n",
    "                all_metrics.append(df)\n",
    "                logger.debug(f\"Processed metrics file: {file.name}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing metrics file {file}: {e}\")\n",
    "        \n",
    "        # Get task accuracy files\n",
    "        task_files = sorted(model_dir.glob(\"task_accuracies_*.csv\"))\n",
    "        logger.info(f\"Found {len(task_files)} task accuracy files for {config_str}\")\n",
    "        \n",
    "        for file in task_files:\n",
    "            try:\n",
    "                df = pd.read_csv(file)\n",
    "                task_cols = [col for col in df.columns if 'task' in col]\n",
    "                for i in range(0, len(task_cols), 2):\n",
    "                    flops_col = task_cols[i]\n",
    "                    acc_col = task_cols[i+1]\n",
    "                    task_num = flops_col.split('_')[1]\n",
    "                    \n",
    "                    task_df = pd.DataFrame({\n",
    "                        'flops': df[flops_col],\n",
    "                        'accuracy': df[acc_col],\n",
    "                        'task': f'Task {task_num}',\n",
    "                        'model_config': config_str\n",
    "                    })\n",
    "                    all_task_data.append(task_df)\n",
    "                logger.debug(f\"Processed task file: {file.name}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing task file {file}: {e}\")\n",
    "    \n",
    "    # Check if we have data to plot\n",
    "    if not all_metrics:\n",
    "        logger.error(\"No metrics data found\")\n",
    "        return\n",
    "    \n",
    "    logger.info(f\"Combining {len(all_metrics)} metric dataframes\")\n",
    "    metrics_df = pd.concat(all_metrics, ignore_index=True)\n",
    "    logger.info(f\"Combined metrics shape: {metrics_df.shape}\")\n",
    "    \n",
    "    # Create epoch bins\n",
    "    try:\n",
    "        metrics_df['epoch_bin'] = pd.qcut(metrics_df['flops'], \n",
    "                                        q=len(metrics_df)//epoch_window, \n",
    "                                        labels=False,\n",
    "                                        duplicates='drop')\n",
    "        logger.info(\"Created epoch bins for metrics\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error creating epoch bins for metrics: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Combine task data if available\n",
    "    if all_task_data:\n",
    "        logger.info(f\"Combining {len(all_task_data)} task dataframes\")\n",
    "        task_df = pd.concat(all_task_data, ignore_index=True)\n",
    "        logger.info(f\"Combined task data shape: {task_df.shape}\")\n",
    "        \n",
    "        try:\n",
    "            task_df['epoch_bin'] = pd.qcut(task_df['flops'], \n",
    "                                         q=len(task_df)//epoch_window, \n",
    "                                         labels=False,\n",
    "                                         duplicates='drop')\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Error creating epoch bins for tasks: {e}\")\n",
    "    \n",
    "    # Create plots\n",
    "    logger.info(\"Creating plots\")\n",
    "    try:\n",
    "        sns.set_style(\"whitegrid\")\n",
    "        sns.set_palette(\"husl\")\n",
    "        \n",
    "        # Create and save each plot separately\n",
    "        # 1. Loss plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.lineplot(data=metrics_df, \n",
    "                    x='flops', \n",
    "                    y='loss',\n",
    "                    hue='model_config',\n",
    "                    errorbar=('ci', confidence_interval))\n",
    "        plt.xscale('log')\n",
    "        plt.yscale('log')\n",
    "        plt.title('Training Loss vs FLOPs')\n",
    "        loss_path = seaborn_dir / f\"loss_plot_window{epoch_window}.png\"\n",
    "        plt.savefig(loss_path, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        logger.info(f\"Saved loss plot to {loss_path}\")\n",
    "        \n",
    "        # 2. Accuracy plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.lineplot(data=metrics_df, \n",
    "                    x='flops', \n",
    "                    y='accuracy',\n",
    "                    hue='model_config',\n",
    "                    errorbar=('ci', confidence_interval))\n",
    "        plt.xscale('log')\n",
    "        plt.title('Overall Accuracy vs FLOPs')\n",
    "        acc_path = seaborn_dir / f\"accuracy_plot_window{epoch_window}.png\"\n",
    "        plt.savefig(acc_path, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        logger.info(f\"Saved accuracy plot to {acc_path}\")\n",
    "        \n",
    "        # 3. Task-specific plot\n",
    "        if all_task_data:\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            sns.lineplot(data=task_df, \n",
    "                        x='flops', \n",
    "                        y='accuracy',\n",
    "                        hue='task',\n",
    "                        style='model_config',\n",
    "                        errorbar=('ci', confidence_interval))\n",
    "            plt.xscale('log')\n",
    "            plt.title('Task-Specific Accuracy vs FLOPs')\n",
    "            task_path = seaborn_dir / f\"task_accuracy_plot_window{epoch_window}.png\"\n",
    "            plt.savefig(task_path, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            logger.info(f\"Saved task-specific plot to {task_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error creating plots: {e}\")\n",
    "        raise\n",
    "    \n",
    "    logger.info(\"Finished creating all plots\")\n",
    "\n",
    "# Example usage\n",
    "exp_dir = Path('/experiments/parity_scaling_flops_1e+12__20250108_232600_v1')\n",
    "# When calling the function\n",
    "#print(f\"Original exp_dir: {exp_dir}\")\n",
    "#print(f\"Absolute exp_dir: {exp_dir.resolve()}\")\n",
    "create_seaborn_plots(exp_dir.resolve(), epoch_window = 100) # untested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for data in: /workspace/project/experiments/parity_scaling_flops_1e+12__20250108_232600_v1\n",
      "\n",
      "Processing configuration: 2x8\n",
      "\n",
      "Processing configuration: 4x16\n",
      "\n",
      "Processing configuration: 6x32\n",
      "\n",
      "Processing configuration: 8x64\n",
      "\n",
      "Processing configuration: 10x128\n",
      "\n",
      "Processing configuration: 12x256\n",
      "\n",
      "Processing configuration: 14x512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43785/2895696578.py:119: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_43785/2895696578.py:123: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  plt.savefig(plot_path, bbox_inches='tight')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved analysis plot to /workspace/project/experiments/parity_scaling_flops_1e+12__20250108_232600_v1/analysis_plots/analysis_comparison.png\n"
     ]
    }
   ],
   "source": [
    "def create_plots_from_saved_data(exp_dir: str | Path, model_configs=model_configs):\n",
    "    \"\"\"\n",
    "    Create plots from saved data in experiment directory.\n",
    "    \n",
    "    Args:\n",
    "        exp_dir: Path to experiment directory (can be string or Path)\n",
    "        model_configs: List of model configurations (defaults to MODEL_CONFIGS)\n",
    "    \"\"\"\n",
    "    # Convert string to Path if necessary\n",
    "    if isinstance(exp_dir, str):\n",
    "        exp_dir = Path(\"experiments\") / exp_dir\n",
    "    elif isinstance(exp_dir, Path):\n",
    "        exp_dir = Path(\"experiments\") / exp_dir.name\n",
    "    \n",
    "    exp_dir = exp_dir.absolute()\n",
    "    print(f\"Looking for data in: {exp_dir}\")\n",
    "    \n",
    "    # Create plots directory\n",
    "    plots_dir = exp_dir / \"analysis_plots\"\n",
    "    plots_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Initialize data storage\n",
    "    all_loss_data = []\n",
    "    all_accuracy_data = []\n",
    "    all_task_accuracy_data = []\n",
    "    \n",
    "    # Process each model configuration\n",
    "    for config in model_configs:\n",
    "        config_str = f\"{config['num_layers']}x{config['hidden_size']}\"\n",
    "        print(f\"\\nProcessing configuration: {config_str}\")\n",
    "        \n",
    "        # Get data directory for this configuration\n",
    "        config_data_dir = exp_dir / \"intermediate_data\" / config_str\n",
    "        if not config_data_dir.exists():\n",
    "            print(f\"No data directory found for configuration {config_str}\")\n",
    "            continue\n",
    "            \n",
    "        # Read metrics files\n",
    "        metrics_files = sorted(config_data_dir.glob(\"metrics_*.csv\"))\n",
    "        if not metrics_files:\n",
    "            print(f\"No metrics files found for configuration {config_str}\")\n",
    "            continue\n",
    "            \n",
    "        # Combine all metrics data for this configuration\n",
    "        config_metrics = []\n",
    "        for file in metrics_files:\n",
    "            df = pd.read_csv(file)\n",
    "            config_metrics.append(df)\n",
    "        \n",
    "        if config_metrics:\n",
    "            metrics_df = pd.concat(config_metrics, ignore_index=True)\n",
    "            metrics_df = metrics_df.sort_values('flops')\n",
    "            \n",
    "            # Store loss and accuracy data\n",
    "            all_loss_data.append((metrics_df['flops'].values, metrics_df['loss'].values))\n",
    "            all_accuracy_data.append((metrics_df['flops'].values, metrics_df['accuracy'].values))\n",
    "            \n",
    "            # Process task accuracy data\n",
    "            task_files = sorted(config_data_dir.glob(\"task_accuracies_*.csv\"))\n",
    "            task_data_dict = {}\n",
    "            \n",
    "            for file in task_files:\n",
    "                df = pd.read_csv(file)\n",
    "                task_cols = [col for col in df.columns if 'task' in col]\n",
    "                for i in range(0, len(task_cols), 2):\n",
    "                    task_idx = int(task_cols[i].split('_')[1])\n",
    "                    if task_idx not in task_data_dict:\n",
    "                        task_data_dict[task_idx] = []\n",
    "                    \n",
    "                    flops = df[task_cols[i]].values\n",
    "                    accuracies = df[task_cols[i+1]].values\n",
    "                    task_data_dict[task_idx].extend(list(zip(flops, accuracies)))\n",
    "            \n",
    "            # Sort task data by FLOPs\n",
    "            for task_idx in task_data_dict:\n",
    "                task_data_dict[task_idx] = sorted(task_data_dict[task_idx], key=lambda x: x[0])\n",
    "            \n",
    "            all_task_accuracy_data.append(task_data_dict)\n",
    "    \n",
    "    # Create plots\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(1, 3, 1)\n",
    "    for i, config in enumerate(model_configs):\n",
    "        if i < len(all_loss_data):\n",
    "            flops, losses = all_loss_data[i]\n",
    "            plt.loglog(flops, losses, label=f'{config[\"num_layers\"]}x{config[\"hidden_size\"]}')\n",
    "    plt.xlabel('Cumulative FLOPs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss vs FLOPs')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot overall accuracy\n",
    "    plt.subplot(1, 3, 2)\n",
    "    for i, config in enumerate(model_configs):\n",
    "        if i < len(all_accuracy_data):\n",
    "            flops, accuracies = all_accuracy_data[i]\n",
    "            plt.semilogx(flops, accuracies, label=f'{config[\"num_layers\"]}x{config[\"hidden_size\"]}')\n",
    "    plt.xlabel('Cumulative FLOPs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy vs FLOPs')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot task-specific accuracies\n",
    "    plt.subplot(1, 3, 3)\n",
    "    for i, config in enumerate(model_configs):\n",
    "        if i < len(all_task_accuracy_data):\n",
    "            task_dict = all_task_accuracy_data[i]\n",
    "            for task_idx in task_dict:\n",
    "                flops, accuracies = zip(*task_dict[task_idx])\n",
    "                plt.semilogx(flops, accuracies, \n",
    "                           label=f'Task {task_idx} - {config[\"num_layers\"]}x{config[\"hidden_size\"]}')\n",
    "    plt.xlabel('Cumulative FLOPs')\n",
    "    plt.ylabel('Task-specific Accuracy')\n",
    "    plt.title('Task-specific Accuracies vs FLOPs')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plot_path = plots_dir / \"analysis_comparison.png\"\n",
    "    plt.savefig(plot_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Saved analysis plot to {plot_path}\")\n",
    "\n",
    "# Example usage:\n",
    "exp_dir = Path('/experiments/parity_scaling_flops_1e+12__20250108_232600_v1')\n",
    "# When calling the function\n",
    "#print(f\"Original exp_dir: {exp_dir}\")\n",
    "#print(f\"Absolute exp_dir: {exp_dir.resolve()}\")\n",
    "create_plots_from_saved_data(exp_dir.resolve()) # untested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
